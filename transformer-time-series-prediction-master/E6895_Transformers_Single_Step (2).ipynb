{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8212,
     "status": "ok",
     "timestamp": 1618000621681,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "u8umvDRoND9t",
    "outputId": "da8a7e9f-7088-4693-d8c7-6f9a344366c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas_datareader) (1.1.5)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas_datareader) (4.2.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas_datareader) (2.23.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas_datareader) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas_datareader) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas_datareader) (2.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas_datareader) (1.15.0)\n",
      "Collecting yfinance\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
      "Collecting lxml>=4.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/4d/6537313bf58fe22b508f08cf3eb86b29b6f9edf68e00454224539421073b/lxml-4.6.3-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5MB 13.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Building wheels for collected packages: yfinance\n",
      "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=f58bce0710a364519bc225ba6f208bccd304031913277fd5d0999e53376843a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n",
      "Successfully built yfinance\n",
      "Installing collected packages: lxml, yfinance\n",
      "  Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "Successfully installed lxml-4.6.3 yfinance-0.1.59\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas_datareader\n",
    "! pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10238,
     "status": "ok",
     "timestamp": 1618000623710,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "KsS1H3-dKLw1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 10392,
     "status": "ok",
     "timestamp": 1618000623867,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "DnpaKciVMcFC"
   },
   "outputs": [],
   "source": [
    "#Create csv for data by the day for past 10 years for AAPL\n",
    "import pandas as pd\n",
    "import yfinance as y\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "tickers = \"AAPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10888,
     "status": "ok",
     "timestamp": 1618000624368,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "T-SOEYHvMeDZ",
    "outputId": "17373b79-58ce-47b3-f375-6df6ab7035fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%***********************]  1 of 1 completed\n",
      "10166\n"
     ]
    }
   ],
   "source": [
    "def z_score(df):\n",
    "    # copy the dataframe\n",
    "    df_std = df.copy()\n",
    "    # apply the z-score method\n",
    "    for column in df_std.columns:\n",
    "        df_std[column] = (df_std[column] - df_std[column].mean()) / df_std[column].std()\n",
    "\n",
    "    return df_std\n",
    "\n",
    "#Choose arbitrary Tech\n",
    "\n",
    "#apple = y.Ticker(tickers)\n",
    "\n",
    "y.pdr_override()\n",
    "apple = pdr.get_data_yahoo(tickers = tickers, period = \"max\", interval = \"1d\", auto_adjust = True, prepost = False)\n",
    "\n",
    "apple = pd.DataFrame(apple)\n",
    "print(apple['Open'].count())\n",
    "\n",
    "apple_train = pd.DataFrame(apple[0:8132])\n",
    "apple_test = pd.DataFrame(apple[8132:])\n",
    "\n",
    "apple_train.to_csv(tickers + \"_min_train.csv\")\n",
    "apple_test.to_csv(tickers + \"_min_test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11070,
     "status": "ok",
     "timestamp": 1618000624554,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "1ImwX2VMPIDX",
    "outputId": "80bee359-023f-4957-d8a9-18bc08f3cba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close     Volume\n",
      "Date                                                         \n",
      "1980-12-12  0.100922  0.101361  0.100922  0.100922  469033600\n",
      "1980-12-15  0.096096  0.096096  0.095657  0.095657  175884800\n",
      "1980-12-16  0.089075  0.089075  0.088636  0.088636  105728000\n",
      "1980-12-17  0.090830  0.091268  0.090830  0.090830   86441600\n",
      "1980-12-18  0.093463  0.093902  0.093463  0.093463   73449600\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8132 entries, 1980-12-12 to 2013-03-12\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Open    8132 non-null   float64\n",
      " 1   High    8132 non-null   float64\n",
      " 2   Low     8132 non-null   float64\n",
      " 3   Close   8132 non-null   float64\n",
      " 4   Volume  8132 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 381.2 KB\n",
      "None\n",
      "Date\n",
      "1980-12-12    0.100922\n",
      "1980-12-15    0.096096\n",
      "1980-12-16    0.089075\n",
      "1980-12-17    0.090830\n",
      "1980-12-18    0.093463\n",
      "Name: Open, dtype: float64\n",
      "Date\n",
      "1980-12-12    1\n",
      "1980-12-15    1\n",
      "1980-12-16    1\n",
      "1980-12-17    1\n",
      "1980-12-18    1\n",
      "Name: Open, dtype: int64\n",
      "8132\n",
      "[-1.         -1.         -1.         ... -1.         -1.\n",
      " -0.87444512]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/content/AAPL_min_train.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data['Open'].head())\n",
    "data['Open'] = 1\n",
    "print(data['Open'].head())\n",
    "print(data['Open'].count())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    #amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "series = scaler.fit_transform(data.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1687854,
     "status": "ok",
     "timestamp": 1618004470499,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "dZPBDg3BPkxI",
    "outputId": "9c8a38d0-f768-4c82-f73b-784cc1647d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   158/  793 batches | lr 0.005000 | 10.19 ms | loss 1.74774 | ppl     5.74\n",
      "| epoch   1 |   316/  793 batches | lr 0.005000 |  9.70 ms | loss 0.00231 | ppl     1.00\n",
      "| epoch   1 |   474/  793 batches | lr 0.005000 |  9.65 ms | loss 0.00024 | ppl     1.00\n",
      "| epoch   1 |   632/  793 batches | lr 0.005000 |  9.71 ms | loss 0.00063 | ppl     1.00\n",
      "| epoch   1 |   790/  793 batches | lr 0.005000 |  9.72 ms | loss 0.01907 | ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  8.32s | valid loss 1.14763 | valid ppl     3.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   158/  793 batches | lr 0.004513 |  9.86 ms | loss 0.03342 | ppl     1.03\n",
      "| epoch   2 |   316/  793 batches | lr 0.004513 |  9.84 ms | loss 0.00027 | ppl     1.00\n",
      "| epoch   2 |   474/  793 batches | lr 0.004513 |  9.82 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch   2 |   632/  793 batches | lr 0.004513 |  9.82 ms | loss 0.00040 | ppl     1.00\n",
      "| epoch   2 |   790/  793 batches | lr 0.004513 |  9.82 ms | loss 0.00820 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  8.36s | valid loss 0.96061 | valid ppl     2.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   158/  793 batches | lr 0.004287 |  9.94 ms | loss 0.04662 | ppl     1.05\n",
      "| epoch   3 |   316/  793 batches | lr 0.004287 |  9.87 ms | loss 0.00034 | ppl     1.00\n",
      "| epoch   3 |   474/  793 batches | lr 0.004287 |  9.90 ms | loss 0.00024 | ppl     1.00\n",
      "| epoch   3 |   632/  793 batches | lr 0.004287 |  9.84 ms | loss 0.00041 | ppl     1.00\n",
      "| epoch   3 |   790/  793 batches | lr 0.004287 |  9.75 ms | loss 0.00575 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  8.38s | valid loss 0.61568 | valid ppl     1.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   158/  793 batches | lr 0.004073 | 10.00 ms | loss 0.02393 | ppl     1.02\n",
      "| epoch   4 |   316/  793 batches | lr 0.004073 |  9.93 ms | loss 0.00036 | ppl     1.00\n",
      "| epoch   4 |   474/  793 batches | lr 0.004073 |  9.87 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch   4 |   632/  793 batches | lr 0.004073 |  9.94 ms | loss 0.00039 | ppl     1.00\n",
      "| epoch   4 |   790/  793 batches | lr 0.004073 |  9.79 ms | loss 0.00583 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  8.39s | valid loss 0.31000 | valid ppl     1.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   158/  793 batches | lr 0.003869 |  9.88 ms | loss 0.01503 | ppl     1.02\n",
      "| epoch   5 |   316/  793 batches | lr 0.003869 |  9.75 ms | loss 0.00024 | ppl     1.00\n",
      "| epoch   5 |   474/  793 batches | lr 0.003869 |  9.76 ms | loss 0.00021 | ppl     1.00\n",
      "| epoch   5 |   632/  793 batches | lr 0.003869 |  9.69 ms | loss 0.00040 | ppl     1.00\n",
      "| epoch   5 |   790/  793 batches | lr 0.003869 |  9.61 ms | loss 0.00490 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  8.26s | valid loss 0.11989 | valid ppl     1.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   158/  793 batches | lr 0.003675 |  9.76 ms | loss 0.00738 | ppl     1.01\n",
      "| epoch   6 |   316/  793 batches | lr 0.003675 |  9.68 ms | loss 0.00018 | ppl     1.00\n",
      "| epoch   6 |   474/  793 batches | lr 0.003675 |  9.65 ms | loss 0.00016 | ppl     1.00\n",
      "| epoch   6 |   632/  793 batches | lr 0.003675 |  9.58 ms | loss 0.00036 | ppl     1.00\n",
      "| epoch   6 |   790/  793 batches | lr 0.003675 |  9.61 ms | loss 0.00473 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  8.18s | valid loss 0.27801 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   158/  793 batches | lr 0.003492 |  9.68 ms | loss 0.01127 | ppl     1.01\n",
      "| epoch   7 |   316/  793 batches | lr 0.003492 |  9.56 ms | loss 0.00018 | ppl     1.00\n",
      "| epoch   7 |   474/  793 batches | lr 0.003492 |  9.65 ms | loss 0.00016 | ppl     1.00\n",
      "| epoch   7 |   632/  793 batches | lr 0.003492 |  9.61 ms | loss 0.00037 | ppl     1.00\n",
      "| epoch   7 |   790/  793 batches | lr 0.003492 |  9.60 ms | loss 0.00512 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  8.14s | valid loss 0.25016 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   158/  793 batches | lr 0.003317 |  9.67 ms | loss 0.01343 | ppl     1.01\n",
      "| epoch   8 |   316/  793 batches | lr 0.003317 |  9.57 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch   8 |   474/  793 batches | lr 0.003317 |  9.57 ms | loss 0.00018 | ppl     1.00\n",
      "| epoch   8 |   632/  793 batches | lr 0.003317 |  9.59 ms | loss 0.00037 | ppl     1.00\n",
      "| epoch   8 |   790/  793 batches | lr 0.003317 |  9.61 ms | loss 0.00426 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  8.12s | valid loss 0.11827 | valid ppl     1.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   158/  793 batches | lr 0.003151 |  9.64 ms | loss 0.00694 | ppl     1.01\n",
      "| epoch   9 |   316/  793 batches | lr 0.003151 |  9.53 ms | loss 0.00015 | ppl     1.00\n",
      "| epoch   9 |   474/  793 batches | lr 0.003151 |  9.51 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch   9 |   632/  793 batches | lr 0.003151 |  9.64 ms | loss 0.00034 | ppl     1.00\n",
      "| epoch   9 |   790/  793 batches | lr 0.003151 |  9.60 ms | loss 0.00377 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  8.12s | valid loss 0.09739 | valid ppl     1.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   158/  793 batches | lr 0.002994 |  9.70 ms | loss 0.00427 | ppl     1.00\n",
      "| epoch  10 |   316/  793 batches | lr 0.002994 |  9.64 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  10 |   474/  793 batches | lr 0.002994 |  9.58 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  10 |   632/  793 batches | lr 0.002994 |  9.60 ms | loss 0.00033 | ppl     1.00\n",
      "| epoch  10 |   790/  793 batches | lr 0.002994 |  9.63 ms | loss 0.00404 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 10.45s | valid loss 0.23228 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   158/  793 batches | lr 0.002844 |  9.57 ms | loss 0.00722 | ppl     1.01\n",
      "| epoch  11 |   316/  793 batches | lr 0.002844 |  9.58 ms | loss 0.00014 | ppl     1.00\n",
      "| epoch  11 |   474/  793 batches | lr 0.002844 |  9.60 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  11 |   632/  793 batches | lr 0.002844 |  9.53 ms | loss 0.00034 | ppl     1.00\n",
      "| epoch  11 |   790/  793 batches | lr 0.002844 |  9.63 ms | loss 0.00356 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  8.13s | valid loss 0.11228 | valid ppl     1.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   158/  793 batches | lr 0.002702 |  9.70 ms | loss 0.00560 | ppl     1.01\n",
      "| epoch  12 |   316/  793 batches | lr 0.002702 |  9.62 ms | loss 0.00014 | ppl     1.00\n",
      "| epoch  12 |   474/  793 batches | lr 0.002702 |  9.61 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  12 |   632/  793 batches | lr 0.002702 |  9.65 ms | loss 0.00033 | ppl     1.00\n",
      "| epoch  12 |   790/  793 batches | lr 0.002702 |  9.80 ms | loss 0.00372 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  8.20s | valid loss 0.03871 | valid ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   158/  793 batches | lr 0.002567 |  9.79 ms | loss 0.00355 | ppl     1.00\n",
      "| epoch  13 |   316/  793 batches | lr 0.002567 |  9.68 ms | loss 0.00016 | ppl     1.00\n",
      "| epoch  13 |   474/  793 batches | lr 0.002567 |  9.66 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  13 |   632/  793 batches | lr 0.002567 |  9.66 ms | loss 0.00034 | ppl     1.00\n",
      "| epoch  13 |   790/  793 batches | lr 0.002567 |  9.75 ms | loss 0.00293 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  8.24s | valid loss 0.02577 | valid ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   158/  793 batches | lr 0.002438 |  9.89 ms | loss 0.00274 | ppl     1.00\n",
      "| epoch  14 |   316/  793 batches | lr 0.002438 |  9.84 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  14 |   474/  793 batches | lr 0.002438 |  9.71 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  14 |   632/  793 batches | lr 0.002438 |  9.74 ms | loss 0.00033 | ppl     1.00\n",
      "| epoch  14 |   790/  793 batches | lr 0.002438 |  9.77 ms | loss 0.00265 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  8.30s | valid loss 0.03307 | valid ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   158/  793 batches | lr 0.002316 |  9.74 ms | loss 0.00235 | ppl     1.00\n",
      "| epoch  15 |   316/  793 batches | lr 0.002316 |  9.66 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  15 |   474/  793 batches | lr 0.002316 |  9.69 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  15 |   632/  793 batches | lr 0.002316 |  9.65 ms | loss 0.00032 | ppl     1.00\n",
      "| epoch  15 |   790/  793 batches | lr 0.002316 |  9.73 ms | loss 0.00266 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  8.22s | valid loss 0.04194 | valid ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   158/  793 batches | lr 0.002201 |  9.73 ms | loss 0.00285 | ppl     1.00\n",
      "| epoch  16 |   316/  793 batches | lr 0.002201 |  9.62 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  16 |   474/  793 batches | lr 0.002201 |  9.62 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  16 |   632/  793 batches | lr 0.002201 |  9.59 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  16 |   790/  793 batches | lr 0.002201 |  9.73 ms | loss 0.00268 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  8.19s | valid loss 0.01552 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   158/  793 batches | lr 0.002091 |  9.73 ms | loss 0.00123 | ppl     1.00\n",
      "| epoch  17 |   316/  793 batches | lr 0.002091 |  9.65 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  17 |   474/  793 batches | lr 0.002091 |  9.65 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch  17 |   632/  793 batches | lr 0.002091 |  9.63 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  17 |   790/  793 batches | lr 0.002091 |  9.67 ms | loss 0.00222 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  8.19s | valid loss 0.04491 | valid ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   158/  793 batches | lr 0.001986 |  9.64 ms | loss 0.00336 | ppl     1.00\n",
      "| epoch  18 |   316/  793 batches | lr 0.001986 |  9.56 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  18 |   474/  793 batches | lr 0.001986 |  9.58 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  18 |   632/  793 batches | lr 0.001986 |  9.62 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  18 |   790/  793 batches | lr 0.001986 |  9.59 ms | loss 0.00248 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  8.13s | valid loss 0.02731 | valid ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   158/  793 batches | lr 0.001887 |  9.62 ms | loss 0.00215 | ppl     1.00\n",
      "| epoch  19 |   316/  793 batches | lr 0.001887 |  9.51 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  19 |   474/  793 batches | lr 0.001887 |  9.49 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  19 |   632/  793 batches | lr 0.001887 |  9.53 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  19 |   790/  793 batches | lr 0.001887 |  9.65 ms | loss 0.00182 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  8.09s | valid loss 0.04775 | valid ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   158/  793 batches | lr 0.001792 |  9.58 ms | loss 0.00308 | ppl     1.00\n",
      "| epoch  20 |   316/  793 batches | lr 0.001792 |  9.51 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  20 |   474/  793 batches | lr 0.001792 |  9.53 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  20 |   632/  793 batches | lr 0.001792 |  9.57 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  20 |   790/  793 batches | lr 0.001792 |  9.67 ms | loss 0.00185 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 10.42s | valid loss 0.03953 | valid ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  21 |   158/  793 batches | lr 0.001703 |  9.57 ms | loss 0.00340 | ppl     1.00\n",
      "| epoch  21 |   316/  793 batches | lr 0.001703 |  9.58 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  21 |   474/  793 batches | lr 0.001703 |  9.53 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  21 |   632/  793 batches | lr 0.001703 |  9.52 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  21 |   790/  793 batches | lr 0.001703 |  9.67 ms | loss 0.00178 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  8.11s | valid loss 0.02425 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |   158/  793 batches | lr 0.001618 |  9.64 ms | loss 0.00255 | ppl     1.00\n",
      "| epoch  22 |   316/  793 batches | lr 0.001618 |  9.54 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  22 |   474/  793 batches | lr 0.001618 |  9.53 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  22 |   632/  793 batches | lr 0.001618 |  9.52 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  22 |   790/  793 batches | lr 0.001618 |  9.67 ms | loss 0.00185 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  8.12s | valid loss 0.04469 | valid ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |   158/  793 batches | lr 0.001537 |  9.59 ms | loss 0.00367 | ppl     1.00\n",
      "| epoch  23 |   316/  793 batches | lr 0.001537 |  9.51 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  23 |   474/  793 batches | lr 0.001537 |  9.53 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  23 |   632/  793 batches | lr 0.001537 |  9.62 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  23 |   790/  793 batches | lr 0.001537 |  9.67 ms | loss 0.00180 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  8.13s | valid loss 0.04062 | valid ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |   158/  793 batches | lr 0.001460 |  9.62 ms | loss 0.00342 | ppl     1.00\n",
      "| epoch  24 |   316/  793 batches | lr 0.001460 |  9.59 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  24 |   474/  793 batches | lr 0.001460 |  9.58 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  24 |   632/  793 batches | lr 0.001460 |  9.65 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  24 |   790/  793 batches | lr 0.001460 |  9.70 ms | loss 0.00154 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  8.16s | valid loss 0.03114 | valid ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |   158/  793 batches | lr 0.001387 |  9.61 ms | loss 0.00294 | ppl     1.00\n",
      "| epoch  25 |   316/  793 batches | lr 0.001387 |  9.59 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  25 |   474/  793 batches | lr 0.001387 |  9.59 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  25 |   632/  793 batches | lr 0.001387 |  9.57 ms | loss 0.00029 | ppl     1.00\n",
      "| epoch  25 |   790/  793 batches | lr 0.001387 |  9.64 ms | loss 0.00156 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  8.13s | valid loss 0.01708 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |   158/  793 batches | lr 0.001318 |  9.67 ms | loss 0.00242 | ppl     1.00\n",
      "| epoch  26 |   316/  793 batches | lr 0.001318 |  9.59 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  26 |   474/  793 batches | lr 0.001318 |  9.52 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  26 |   632/  793 batches | lr 0.001318 |  9.59 ms | loss 0.00029 | ppl     1.00\n",
      "| epoch  26 |   790/  793 batches | lr 0.001318 |  9.65 ms | loss 0.00137 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  8.14s | valid loss 0.01375 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |   158/  793 batches | lr 0.001252 |  9.64 ms | loss 0.00156 | ppl     1.00\n",
      "| epoch  27 |   316/  793 batches | lr 0.001252 |  9.53 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  27 |   474/  793 batches | lr 0.001252 |  9.54 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  27 |   632/  793 batches | lr 0.001252 |  9.54 ms | loss 0.00026 | ppl     1.00\n",
      "| epoch  27 |   790/  793 batches | lr 0.001252 |  9.64 ms | loss 0.00139 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  8.12s | valid loss 0.01076 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |   158/  793 batches | lr 0.001189 |  9.61 ms | loss 0.00147 | ppl     1.00\n",
      "| epoch  28 |   316/  793 batches | lr 0.001189 |  9.57 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  28 |   474/  793 batches | lr 0.001189 |  9.57 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  28 |   632/  793 batches | lr 0.001189 |  9.56 ms | loss 0.00029 | ppl     1.00\n",
      "| epoch  28 |   790/  793 batches | lr 0.001189 |  9.67 ms | loss 0.00135 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  8.13s | valid loss 0.01337 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |   158/  793 batches | lr 0.001130 |  9.64 ms | loss 0.00160 | ppl     1.00\n",
      "| epoch  29 |   316/  793 batches | lr 0.001130 |  9.56 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  29 |   474/  793 batches | lr 0.001130 |  9.53 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  29 |   632/  793 batches | lr 0.001130 |  9.61 ms | loss 0.00025 | ppl     1.00\n",
      "| epoch  29 |   790/  793 batches | lr 0.001130 |  9.69 ms | loss 0.00134 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  8.14s | valid loss 0.01719 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |   158/  793 batches | lr 0.001073 |  9.77 ms | loss 0.00183 | ppl     1.00\n",
      "| epoch  30 |   316/  793 batches | lr 0.001073 |  9.63 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  30 |   474/  793 batches | lr 0.001073 |  9.54 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  30 |   632/  793 batches | lr 0.001073 |  9.62 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch  30 |   790/  793 batches | lr 0.001073 |  9.70 ms | loss 0.00154 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 10.61s | valid loss 0.01975 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  31 |   158/  793 batches | lr 0.001020 |  9.65 ms | loss 0.00178 | ppl     1.00\n",
      "| epoch  31 |   316/  793 batches | lr 0.001020 |  9.64 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  31 |   474/  793 batches | lr 0.001020 |  9.58 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  31 |   632/  793 batches | lr 0.001020 |  9.62 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch  31 |   790/  793 batches | lr 0.001020 |  9.70 ms | loss 0.00125 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  8.17s | valid loss 0.01389 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |   158/  793 batches | lr 0.000969 |  9.59 ms | loss 0.00146 | ppl     1.00\n",
      "| epoch  32 |   316/  793 batches | lr 0.000969 |  9.62 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  32 |   474/  793 batches | lr 0.000969 |  9.57 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  32 |   632/  793 batches | lr 0.000969 |  9.64 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch  32 |   790/  793 batches | lr 0.000969 |  9.68 ms | loss 0.00123 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  8.15s | valid loss 0.01212 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |   158/  793 batches | lr 0.000920 |  9.64 ms | loss 0.00144 | ppl     1.00\n",
      "| epoch  33 |   316/  793 batches | lr 0.000920 |  9.54 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  33 |   474/  793 batches | lr 0.000920 |  9.55 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  33 |   632/  793 batches | lr 0.000920 |  9.55 ms | loss 0.00019 | ppl     1.00\n",
      "| epoch  33 |   790/  793 batches | lr 0.000920 |  9.63 ms | loss 0.00116 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  8.12s | valid loss 0.02471 | valid ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |   158/  793 batches | lr 0.000874 |  9.61 ms | loss 0.00135 | ppl     1.00\n",
      "| epoch  34 |   316/  793 batches | lr 0.000874 |  9.58 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  34 |   474/  793 batches | lr 0.000874 |  9.58 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  34 |   632/  793 batches | lr 0.000874 |  9.57 ms | loss 0.00028 | ppl     1.00\n",
      "| epoch  34 |   790/  793 batches | lr 0.000874 |  9.66 ms | loss 0.00109 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  8.13s | valid loss 0.00803 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |   158/  793 batches | lr 0.000830 |  9.68 ms | loss 0.00138 | ppl     1.00\n",
      "| epoch  35 |   316/  793 batches | lr 0.000830 |  9.54 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  35 |   474/  793 batches | lr 0.000830 |  9.54 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  35 |   632/  793 batches | lr 0.000830 |  9.63 ms | loss 0.00019 | ppl     1.00\n",
      "| epoch  35 |   790/  793 batches | lr 0.000830 |  9.66 ms | loss 0.00115 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  8.14s | valid loss 0.01590 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |   158/  793 batches | lr 0.000789 |  9.65 ms | loss 0.00124 | ppl     1.00\n",
      "| epoch  36 |   316/  793 batches | lr 0.000789 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  36 |   474/  793 batches | lr 0.000789 |  9.57 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  36 |   632/  793 batches | lr 0.000789 |  9.57 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch  36 |   790/  793 batches | lr 0.000789 |  9.70 ms | loss 0.00113 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  8.16s | valid loss 0.00965 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |   158/  793 batches | lr 0.000749 |  9.66 ms | loss 0.00114 | ppl     1.00\n",
      "| epoch  37 |   316/  793 batches | lr 0.000749 |  9.63 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  37 |   474/  793 batches | lr 0.000749 |  9.56 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  37 |   632/  793 batches | lr 0.000749 |  9.61 ms | loss 0.00018 | ppl     1.00\n",
      "| epoch  37 |   790/  793 batches | lr 0.000749 |  9.79 ms | loss 0.00116 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  8.18s | valid loss 0.02070 | valid ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |   158/  793 batches | lr 0.000712 |  9.66 ms | loss 0.00097 | ppl     1.00\n",
      "| epoch  38 |   316/  793 batches | lr 0.000712 |  9.62 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  38 |   474/  793 batches | lr 0.000712 |  9.54 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  38 |   632/  793 batches | lr 0.000712 |  9.62 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch  38 |   790/  793 batches | lr 0.000712 |  9.64 ms | loss 0.00111 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  8.15s | valid loss 0.01113 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |   158/  793 batches | lr 0.000676 |  9.65 ms | loss 0.00110 | ppl     1.00\n",
      "| epoch  39 |   316/  793 batches | lr 0.000676 |  9.67 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  39 |   474/  793 batches | lr 0.000676 |  9.61 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  39 |   632/  793 batches | lr 0.000676 |  9.59 ms | loss 0.00016 | ppl     1.00\n",
      "| epoch  39 |   790/  793 batches | lr 0.000676 |  9.70 ms | loss 0.00110 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  8.18s | valid loss 0.01292 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |   158/  793 batches | lr 0.000643 |  9.70 ms | loss 0.00099 | ppl     1.00\n",
      "| epoch  40 |   316/  793 batches | lr 0.000643 |  9.64 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  40 |   474/  793 batches | lr 0.000643 |  9.71 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  40 |   632/  793 batches | lr 0.000643 |  9.63 ms | loss 0.00014 | ppl     1.00\n",
      "| epoch  40 |   790/  793 batches | lr 0.000643 |  9.71 ms | loss 0.00119 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 10.64s | valid loss 0.01221 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  41 |   158/  793 batches | lr 0.000610 |  9.62 ms | loss 0.00081 | ppl     1.00\n",
      "| epoch  41 |   316/  793 batches | lr 0.000610 |  9.60 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  41 |   474/  793 batches | lr 0.000610 |  9.62 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  41 |   632/  793 batches | lr 0.000610 |  9.60 ms | loss 0.00019 | ppl     1.00\n",
      "| epoch  41 |   790/  793 batches | lr 0.000610 |  9.68 ms | loss 0.00117 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  8.15s | valid loss 0.00463 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |   158/  793 batches | lr 0.000580 |  9.73 ms | loss 0.00071 | ppl     1.00\n",
      "| epoch  42 |   316/  793 batches | lr 0.000580 |  9.53 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  42 |   474/  793 batches | lr 0.000580 |  9.66 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  42 |   632/  793 batches | lr 0.000580 |  9.65 ms | loss 0.00017 | ppl     1.00\n",
      "| epoch  42 |   790/  793 batches | lr 0.000580 |  9.67 ms | loss 0.00117 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  8.18s | valid loss 0.00722 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |   158/  793 batches | lr 0.000551 |  9.61 ms | loss 0.00076 | ppl     1.00\n",
      "| epoch  43 |   316/  793 batches | lr 0.000551 |  9.61 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  43 |   474/  793 batches | lr 0.000551 |  9.67 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  43 |   632/  793 batches | lr 0.000551 |  9.65 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  43 |   790/  793 batches | lr 0.000551 |  9.67 ms | loss 0.00117 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  8.17s | valid loss 0.00322 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |   158/  793 batches | lr 0.000523 |  9.72 ms | loss 0.00035 | ppl     1.00\n",
      "| epoch  44 |   316/  793 batches | lr 0.000523 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  44 |   474/  793 batches | lr 0.000523 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  44 |   632/  793 batches | lr 0.000523 |  9.65 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  44 |   790/  793 batches | lr 0.000523 |  9.64 ms | loss 0.00107 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  8.36s | valid loss 0.00523 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |   158/  793 batches | lr 0.000497 |  9.72 ms | loss 0.00045 | ppl     1.00\n",
      "| epoch  45 |   316/  793 batches | lr 0.000497 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  45 |   474/  793 batches | lr 0.000497 |  9.58 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  45 |   632/  793 batches | lr 0.000497 |  9.63 ms | loss 0.00015 | ppl     1.00\n",
      "| epoch  45 |   790/  793 batches | lr 0.000497 |  9.74 ms | loss 0.00097 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  8.18s | valid loss 0.00644 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |   158/  793 batches | lr 0.000472 |  9.69 ms | loss 0.00048 | ppl     1.00\n",
      "| epoch  46 |   316/  793 batches | lr 0.000472 |  9.58 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  46 |   474/  793 batches | lr 0.000472 |  9.61 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  46 |   632/  793 batches | lr 0.000472 |  9.67 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  46 |   790/  793 batches | lr 0.000472 |  9.70 ms | loss 0.00094 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  8.18s | valid loss 0.00786 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |   158/  793 batches | lr 0.000449 |  9.75 ms | loss 0.00049 | ppl     1.00\n",
      "| epoch  47 |   316/  793 batches | lr 0.000449 |  9.65 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  47 |   474/  793 batches | lr 0.000449 |  9.65 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  47 |   632/  793 batches | lr 0.000449 |  9.58 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  47 |   790/  793 batches | lr 0.000449 |  9.68 ms | loss 0.00090 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  8.19s | valid loss 0.00771 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |   158/  793 batches | lr 0.000426 |  9.66 ms | loss 0.00049 | ppl     1.00\n",
      "| epoch  48 |   316/  793 batches | lr 0.000426 |  9.62 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  48 |   474/  793 batches | lr 0.000426 |  9.67 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  48 |   632/  793 batches | lr 0.000426 |  9.65 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  48 |   790/  793 batches | lr 0.000426 |  9.79 ms | loss 0.00089 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  8.20s | valid loss 0.00725 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |   158/  793 batches | lr 0.000405 |  9.74 ms | loss 0.00048 | ppl     1.00\n",
      "| epoch  49 |   316/  793 batches | lr 0.000405 |  9.67 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  49 |   474/  793 batches | lr 0.000405 |  9.65 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  49 |   632/  793 batches | lr 0.000405 |  9.69 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch  49 |   790/  793 batches | lr 0.000405 |  9.76 ms | loss 0.00088 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  8.23s | valid loss 0.00748 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |   158/  793 batches | lr 0.000385 |  9.68 ms | loss 0.00053 | ppl     1.00\n",
      "| epoch  50 |   316/  793 batches | lr 0.000385 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  50 |   474/  793 batches | lr 0.000385 |  9.59 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  50 |   632/  793 batches | lr 0.000385 |  9.69 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  50 |   790/  793 batches | lr 0.000385 |  9.73 ms | loss 0.00084 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 10.60s | valid loss 0.00564 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  51 |   158/  793 batches | lr 0.000365 |  9.66 ms | loss 0.00043 | ppl     1.00\n",
      "| epoch  51 |   316/  793 batches | lr 0.000365 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  51 |   474/  793 batches | lr 0.000365 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  51 |   632/  793 batches | lr 0.000365 |  9.70 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  51 |   790/  793 batches | lr 0.000365 |  9.77 ms | loss 0.00087 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  8.19s | valid loss 0.00587 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |   158/  793 batches | lr 0.000347 |  9.76 ms | loss 0.00045 | ppl     1.00\n",
      "| epoch  52 |   316/  793 batches | lr 0.000347 |  9.66 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  52 |   474/  793 batches | lr 0.000347 |  9.57 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  52 |   632/  793 batches | lr 0.000347 |  9.64 ms | loss 0.00014 | ppl     1.00\n",
      "| epoch  52 |   790/  793 batches | lr 0.000347 |  9.74 ms | loss 0.00081 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  8.20s | valid loss 0.00546 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |   158/  793 batches | lr 0.000330 |  9.70 ms | loss 0.00040 | ppl     1.00\n",
      "| epoch  53 |   316/  793 batches | lr 0.000330 |  9.58 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  53 |   474/  793 batches | lr 0.000330 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  53 |   632/  793 batches | lr 0.000330 |  9.69 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch  53 |   790/  793 batches | lr 0.000330 |  9.72 ms | loss 0.00083 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  8.19s | valid loss 0.00514 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |   158/  793 batches | lr 0.000313 |  9.71 ms | loss 0.00039 | ppl     1.00\n",
      "| epoch  54 |   316/  793 batches | lr 0.000313 |  9.75 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  54 |   474/  793 batches | lr 0.000313 |  9.63 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  54 |   632/  793 batches | lr 0.000313 |  9.61 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  54 |   790/  793 batches | lr 0.000313 |  9.74 ms | loss 0.00081 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  8.21s | valid loss 0.00455 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |   158/  793 batches | lr 0.000298 |  9.70 ms | loss 0.00031 | ppl     1.00\n",
      "| epoch  55 |   316/  793 batches | lr 0.000298 |  9.64 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  55 |   474/  793 batches | lr 0.000298 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  55 |   632/  793 batches | lr 0.000298 |  9.64 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch  55 |   790/  793 batches | lr 0.000298 |  9.75 ms | loss 0.00083 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  8.19s | valid loss 0.00480 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |   158/  793 batches | lr 0.000283 |  9.73 ms | loss 0.00032 | ppl     1.00\n",
      "| epoch  56 |   316/  793 batches | lr 0.000283 |  9.66 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  56 |   474/  793 batches | lr 0.000283 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  56 |   632/  793 batches | lr 0.000283 |  9.70 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  56 |   790/  793 batches | lr 0.000283 |  9.77 ms | loss 0.00083 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  8.24s | valid loss 0.00441 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |   158/  793 batches | lr 0.000269 |  9.71 ms | loss 0.00025 | ppl     1.00\n",
      "| epoch  57 |   316/  793 batches | lr 0.000269 |  9.64 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  57 |   474/  793 batches | lr 0.000269 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  57 |   632/  793 batches | lr 0.000269 |  9.65 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  57 |   790/  793 batches | lr 0.000269 |  9.70 ms | loss 0.00081 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  8.19s | valid loss 0.00668 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |   158/  793 batches | lr 0.000255 |  9.61 ms | loss 0.00030 | ppl     1.00\n",
      "| epoch  58 |   316/  793 batches | lr 0.000255 |  9.69 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  58 |   474/  793 batches | lr 0.000255 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  58 |   632/  793 batches | lr 0.000255 |  9.64 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  58 |   790/  793 batches | lr 0.000255 |  9.75 ms | loss 0.00079 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  8.18s | valid loss 0.00626 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |   158/  793 batches | lr 0.000242 |  9.65 ms | loss 0.00028 | ppl     1.00\n",
      "| epoch  59 |   316/  793 batches | lr 0.000242 |  9.54 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  59 |   474/  793 batches | lr 0.000242 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  59 |   632/  793 batches | lr 0.000242 |  9.67 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  59 |   790/  793 batches | lr 0.000242 |  9.67 ms | loss 0.00077 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  8.16s | valid loss 0.00721 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |   158/  793 batches | lr 0.000230 |  9.72 ms | loss 0.00032 | ppl     1.00\n",
      "| epoch  60 |   316/  793 batches | lr 0.000230 |  9.65 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  60 |   474/  793 batches | lr 0.000230 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  60 |   632/  793 batches | lr 0.000230 |  9.69 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  60 |   790/  793 batches | lr 0.000230 |  9.73 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 10.64s | valid loss 0.00538 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  61 |   158/  793 batches | lr 0.000219 |  9.67 ms | loss 0.00026 | ppl     1.00\n",
      "| epoch  61 |   316/  793 batches | lr 0.000219 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  61 |   474/  793 batches | lr 0.000219 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  61 |   632/  793 batches | lr 0.000219 |  9.65 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch  61 |   790/  793 batches | lr 0.000219 |  9.67 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  8.18s | valid loss 0.00608 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |   158/  793 batches | lr 0.000208 |  9.68 ms | loss 0.00029 | ppl     1.00\n",
      "| epoch  62 |   316/  793 batches | lr 0.000208 |  9.59 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  62 |   474/  793 batches | lr 0.000208 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  62 |   632/  793 batches | lr 0.000208 |  9.63 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  62 |   790/  793 batches | lr 0.000208 |  9.70 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  8.17s | valid loss 0.00499 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |   158/  793 batches | lr 0.000197 |  9.67 ms | loss 0.00024 | ppl     1.00\n",
      "| epoch  63 |   316/  793 batches | lr 0.000197 |  9.60 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  63 |   474/  793 batches | lr 0.000197 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  63 |   632/  793 batches | lr 0.000197 |  9.60 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  63 |   790/  793 batches | lr 0.000197 |  9.73 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  8.17s | valid loss 0.00597 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |   158/  793 batches | lr 0.000188 |  9.71 ms | loss 0.00027 | ppl     1.00\n",
      "| epoch  64 |   316/  793 batches | lr 0.000188 |  9.61 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch  64 |   474/  793 batches | lr 0.000188 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  64 |   632/  793 batches | lr 0.000188 |  9.67 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  64 |   790/  793 batches | lr 0.000188 |  9.76 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  8.20s | valid loss 0.00553 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |   158/  793 batches | lr 0.000178 |  9.64 ms | loss 0.00023 | ppl     1.00\n",
      "| epoch  65 |   316/  793 batches | lr 0.000178 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  65 |   474/  793 batches | lr 0.000178 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  65 |   632/  793 batches | lr 0.000178 |  9.65 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  65 |   790/  793 batches | lr 0.000178 |  9.67 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  8.16s | valid loss 0.00685 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |   158/  793 batches | lr 0.000169 |  9.64 ms | loss 0.00027 | ppl     1.00\n",
      "| epoch  66 |   316/  793 batches | lr 0.000169 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  66 |   474/  793 batches | lr 0.000169 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  66 |   632/  793 batches | lr 0.000169 |  9.67 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  66 |   790/  793 batches | lr 0.000169 |  9.66 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  8.16s | valid loss 0.00501 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |   158/  793 batches | lr 0.000161 |  9.66 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch  67 |   316/  793 batches | lr 0.000161 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  67 |   474/  793 batches | lr 0.000161 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  67 |   632/  793 batches | lr 0.000161 |  9.63 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  67 |   790/  793 batches | lr 0.000161 |  9.73 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  8.18s | valid loss 0.00596 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |   158/  793 batches | lr 0.000153 |  9.73 ms | loss 0.00026 | ppl     1.00\n",
      "| epoch  68 |   316/  793 batches | lr 0.000153 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  68 |   474/  793 batches | lr 0.000153 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  68 |   632/  793 batches | lr 0.000153 |  9.70 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  68 |   790/  793 batches | lr 0.000153 |  9.71 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  8.20s | valid loss 0.00554 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |   158/  793 batches | lr 0.000145 |  9.65 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch  69 |   316/  793 batches | lr 0.000145 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  69 |   474/  793 batches | lr 0.000145 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  69 |   632/  793 batches | lr 0.000145 |  9.65 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  69 |   790/  793 batches | lr 0.000145 |  9.67 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  8.18s | valid loss 0.00626 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |   158/  793 batches | lr 0.000138 |  9.62 ms | loss 0.00026 | ppl     1.00\n",
      "| epoch  70 |   316/  793 batches | lr 0.000138 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  70 |   474/  793 batches | lr 0.000138 |  9.56 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  70 |   632/  793 batches | lr 0.000138 |  9.63 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  70 |   790/  793 batches | lr 0.000138 |  9.67 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 10.50s | valid loss 0.00445 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  71 |   158/  793 batches | lr 0.000131 |  9.65 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch  71 |   316/  793 batches | lr 0.000131 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  71 |   474/  793 batches | lr 0.000131 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  71 |   632/  793 batches | lr 0.000131 |  9.63 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch  71 |   790/  793 batches | lr 0.000131 |  9.74 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  8.18s | valid loss 0.00445 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |   158/  793 batches | lr 0.000124 |  9.65 ms | loss 0.00023 | ppl     1.00\n",
      "| epoch  72 |   316/  793 batches | lr 0.000124 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  72 |   474/  793 batches | lr 0.000124 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  72 |   632/  793 batches | lr 0.000124 |  9.61 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  72 |   790/  793 batches | lr 0.000124 |  9.70 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  8.16s | valid loss 0.00351 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 |   158/  793 batches | lr 0.000118 |  9.67 ms | loss 0.00021 | ppl     1.00\n",
      "| epoch  73 |   316/  793 batches | lr 0.000118 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  73 |   474/  793 batches | lr 0.000118 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  73 |   632/  793 batches | lr 0.000118 |  9.60 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  73 |   790/  793 batches | lr 0.000118 |  9.69 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  8.16s | valid loss 0.00406 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |   158/  793 batches | lr 0.000112 |  9.62 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch  74 |   316/  793 batches | lr 0.000112 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  74 |   474/  793 batches | lr 0.000112 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  74 |   632/  793 batches | lr 0.000112 |  9.71 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  74 |   790/  793 batches | lr 0.000112 |  9.65 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  8.18s | valid loss 0.00427 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |   158/  793 batches | lr 0.000107 |  9.66 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch  75 |   316/  793 batches | lr 0.000107 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  75 |   474/  793 batches | lr 0.000107 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  75 |   632/  793 batches | lr 0.000107 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  75 |   790/  793 batches | lr 0.000107 |  9.70 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  8.19s | valid loss 0.00457 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |   158/  793 batches | lr 0.000101 |  9.65 ms | loss 0.00022 | ppl     1.00\n",
      "| epoch  76 |   316/  793 batches | lr 0.000101 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  76 |   474/  793 batches | lr 0.000101 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  76 |   632/  793 batches | lr 0.000101 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  76 |   790/  793 batches | lr 0.000101 |  9.69 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  8.17s | valid loss 0.00335 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |   158/  793 batches | lr 0.000096 |  9.64 ms | loss 0.00020 | ppl     1.00\n",
      "| epoch  77 |   316/  793 batches | lr 0.000096 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  77 |   474/  793 batches | lr 0.000096 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  77 |   632/  793 batches | lr 0.000096 |  9.59 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  77 |   790/  793 batches | lr 0.000096 |  9.76 ms | loss 0.00076 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  8.17s | valid loss 0.00283 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |   158/  793 batches | lr 0.000091 |  9.68 ms | loss 0.00021 | ppl     1.00\n",
      "| epoch  78 |   316/  793 batches | lr 0.000091 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  78 |   474/  793 batches | lr 0.000091 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  78 |   632/  793 batches | lr 0.000091 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  78 |   790/  793 batches | lr 0.000091 |  9.70 ms | loss 0.00076 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  8.18s | valid loss 0.00180 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |   158/  793 batches | lr 0.000087 |  9.71 ms | loss 0.00019 | ppl     1.00\n",
      "| epoch  79 |   316/  793 batches | lr 0.000087 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  79 |   474/  793 batches | lr 0.000087 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  79 |   632/  793 batches | lr 0.000087 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  79 |   790/  793 batches | lr 0.000087 |  9.72 ms | loss 0.00076 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  8.20s | valid loss 0.00156 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |   158/  793 batches | lr 0.000083 |  9.71 ms | loss 0.00019 | ppl     1.00\n",
      "| epoch  80 |   316/  793 batches | lr 0.000083 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  80 |   474/  793 batches | lr 0.000083 |  9.54 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  80 |   632/  793 batches | lr 0.000083 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  80 |   790/  793 batches | lr 0.000083 |  9.67 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 10.58s | valid loss 0.00152 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  81 |   158/  793 batches | lr 0.000078 |  9.65 ms | loss 0.00017 | ppl     1.00\n",
      "| epoch  81 |   316/  793 batches | lr 0.000078 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  81 |   474/  793 batches | lr 0.000078 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  81 |   632/  793 batches | lr 0.000078 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  81 |   790/  793 batches | lr 0.000078 |  9.66 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  8.16s | valid loss 0.00199 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |   158/  793 batches | lr 0.000075 |  9.68 ms | loss 0.00017 | ppl     1.00\n",
      "| epoch  82 |   316/  793 batches | lr 0.000075 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  82 |   474/  793 batches | lr 0.000075 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  82 |   632/  793 batches | lr 0.000075 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  82 |   790/  793 batches | lr 0.000075 |  9.68 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  8.19s | valid loss 0.00268 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |   158/  793 batches | lr 0.000071 |  9.68 ms | loss 0.00016 | ppl     1.00\n",
      "| epoch  83 |   316/  793 batches | lr 0.000071 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  83 |   474/  793 batches | lr 0.000071 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  83 |   632/  793 batches | lr 0.000071 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  83 |   790/  793 batches | lr 0.000071 |  9.68 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  8.19s | valid loss 0.00308 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |   158/  793 batches | lr 0.000067 |  9.64 ms | loss 0.00016 | ppl     1.00\n",
      "| epoch  84 |   316/  793 batches | lr 0.000067 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  84 |   474/  793 batches | lr 0.000067 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  84 |   632/  793 batches | lr 0.000067 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  84 |   790/  793 batches | lr 0.000067 |  9.72 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  8.19s | valid loss 0.00321 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 |   158/  793 batches | lr 0.000064 |  9.67 ms | loss 0.00015 | ppl     1.00\n",
      "| epoch  85 |   316/  793 batches | lr 0.000064 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  85 |   474/  793 batches | lr 0.000064 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  85 |   632/  793 batches | lr 0.000064 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  85 |   790/  793 batches | lr 0.000064 |  9.72 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  8.20s | valid loss 0.00336 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |   158/  793 batches | lr 0.000061 |  9.72 ms | loss 0.00015 | ppl     1.00\n",
      "| epoch  86 |   316/  793 batches | lr 0.000061 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  86 |   474/  793 batches | lr 0.000061 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  86 |   632/  793 batches | lr 0.000061 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  86 |   790/  793 batches | lr 0.000061 |  9.66 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  8.18s | valid loss 0.00352 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |   158/  793 batches | lr 0.000058 |  9.72 ms | loss 0.00014 | ppl     1.00\n",
      "| epoch  87 |   316/  793 batches | lr 0.000058 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  87 |   474/  793 batches | lr 0.000058 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  87 |   632/  793 batches | lr 0.000058 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch  87 |   790/  793 batches | lr 0.000058 |  9.76 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  8.21s | valid loss 0.00358 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |   158/  793 batches | lr 0.000055 |  9.70 ms | loss 0.00014 | ppl     1.00\n",
      "| epoch  88 |   316/  793 batches | lr 0.000055 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  88 |   474/  793 batches | lr 0.000055 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  88 |   632/  793 batches | lr 0.000055 |  9.68 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  88 |   790/  793 batches | lr 0.000055 |  9.68 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  8.19s | valid loss 0.00353 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |   158/  793 batches | lr 0.000052 |  9.69 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  89 |   316/  793 batches | lr 0.000052 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  89 |   474/  793 batches | lr 0.000052 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  89 |   632/  793 batches | lr 0.000052 |  9.62 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  89 |   790/  793 batches | lr 0.000052 |  9.68 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  8.17s | valid loss 0.00355 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |   158/  793 batches | lr 0.000049 |  9.77 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  90 |   316/  793 batches | lr 0.000049 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  90 |   474/  793 batches | lr 0.000049 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  90 |   632/  793 batches | lr 0.000049 |  9.65 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  90 |   790/  793 batches | lr 0.000049 |  9.69 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 10.61s | valid loss 0.00361 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  91 |   158/  793 batches | lr 0.000047 |  9.68 ms | loss 0.00013 | ppl     1.00\n",
      "| epoch  91 |   316/  793 batches | lr 0.000047 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  91 |   474/  793 batches | lr 0.000047 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  91 |   632/  793 batches | lr 0.000047 |  9.65 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  91 |   790/  793 batches | lr 0.000047 |  9.68 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  8.17s | valid loss 0.00338 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |   158/  793 batches | lr 0.000045 |  9.62 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  92 |   316/  793 batches | lr 0.000045 |  9.56 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  92 |   474/  793 batches | lr 0.000045 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  92 |   632/  793 batches | lr 0.000045 |  9.66 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  92 |   790/  793 batches | lr 0.000045 |  9.68 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  8.16s | valid loss 0.00339 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |   158/  793 batches | lr 0.000042 |  9.73 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  93 |   316/  793 batches | lr 0.000042 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  93 |   474/  793 batches | lr 0.000042 |  9.56 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  93 |   632/  793 batches | lr 0.000042 |  9.60 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  93 |   790/  793 batches | lr 0.000042 |  9.66 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  8.18s | valid loss 0.00327 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |   158/  793 batches | lr 0.000040 |  9.62 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  94 |   316/  793 batches | lr 0.000040 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  94 |   474/  793 batches | lr 0.000040 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  94 |   632/  793 batches | lr 0.000040 |  9.63 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  94 |   790/  793 batches | lr 0.000040 |  9.68 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  8.17s | valid loss 0.00314 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |   158/  793 batches | lr 0.000038 |  9.68 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  95 |   316/  793 batches | lr 0.000038 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  95 |   474/  793 batches | lr 0.000038 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  95 |   632/  793 batches | lr 0.000038 |  9.69 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  95 |   790/  793 batches | lr 0.000038 |  9.67 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  8.20s | valid loss 0.00295 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |   158/  793 batches | lr 0.000036 |  9.70 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  96 |   316/  793 batches | lr 0.000036 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  96 |   474/  793 batches | lr 0.000036 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  96 |   632/  793 batches | lr 0.000036 |  9.66 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  96 |   790/  793 batches | lr 0.000036 |  9.69 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  8.19s | valid loss 0.00296 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 |   158/  793 batches | lr 0.000035 |  9.71 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  97 |   316/  793 batches | lr 0.000035 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch  97 |   474/  793 batches | lr 0.000035 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  97 |   632/  793 batches | lr 0.000035 |  9.64 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  97 |   790/  793 batches | lr 0.000035 |  9.64 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  8.19s | valid loss 0.00277 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |   158/  793 batches | lr 0.000033 |  9.63 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  98 |   316/  793 batches | lr 0.000033 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  98 |   474/  793 batches | lr 0.000033 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  98 |   632/  793 batches | lr 0.000033 |  9.61 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  98 |   790/  793 batches | lr 0.000033 |  9.73 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  8.29s | valid loss 0.00273 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |   158/  793 batches | lr 0.000031 |  9.64 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch  99 |   316/  793 batches | lr 0.000031 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  99 |   474/  793 batches | lr 0.000031 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch  99 |   632/  793 batches | lr 0.000031 |  9.68 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch  99 |   790/  793 batches | lr 0.000031 |  9.72 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  8.19s | valid loss 0.00255 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |   158/  793 batches | lr 0.000030 |  9.72 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch 100 |   316/  793 batches | lr 0.000030 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 100 |   474/  793 batches | lr 0.000030 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 100 |   632/  793 batches | lr 0.000030 |  9.64 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 100 |   790/  793 batches | lr 0.000030 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time: 10.58s | valid loss 0.00251 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 101 |   158/  793 batches | lr 0.000028 |  9.61 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch 101 |   316/  793 batches | lr 0.000028 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 101 |   474/  793 batches | lr 0.000028 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 101 |   632/  793 batches | lr 0.000028 |  9.62 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 101 |   790/  793 batches | lr 0.000028 |  9.67 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 101 | time:  8.16s | valid loss 0.00266 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 102 |   158/  793 batches | lr 0.000027 |  9.64 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch 102 |   316/  793 batches | lr 0.000027 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 102 |   474/  793 batches | lr 0.000027 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 102 |   632/  793 batches | lr 0.000027 |  9.63 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 102 |   790/  793 batches | lr 0.000027 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 102 | time:  8.17s | valid loss 0.00259 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 103 |   158/  793 batches | lr 0.000025 |  9.65 ms | loss 0.00012 | ppl     1.00\n",
      "| epoch 103 |   316/  793 batches | lr 0.000025 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 103 |   474/  793 batches | lr 0.000025 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 103 |   632/  793 batches | lr 0.000025 |  9.58 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 103 |   790/  793 batches | lr 0.000025 |  9.66 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 103 | time:  8.15s | valid loss 0.00261 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 104 |   158/  793 batches | lr 0.000024 |  9.63 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch 104 |   316/  793 batches | lr 0.000024 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 104 |   474/  793 batches | lr 0.000024 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 104 |   632/  793 batches | lr 0.000024 |  9.64 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 104 |   790/  793 batches | lr 0.000024 |  9.62 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 104 | time:  8.16s | valid loss 0.00262 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 105 |   158/  793 batches | lr 0.000023 |  9.70 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch 105 |   316/  793 batches | lr 0.000023 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 105 |   474/  793 batches | lr 0.000023 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 105 |   632/  793 batches | lr 0.000023 |  9.62 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 105 |   790/  793 batches | lr 0.000023 |  9.62 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 105 | time:  8.16s | valid loss 0.00257 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 106 |   158/  793 batches | lr 0.000022 |  9.64 ms | loss 0.00011 | ppl     1.00\n",
      "| epoch 106 |   316/  793 batches | lr 0.000022 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 106 |   474/  793 batches | lr 0.000022 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 106 |   632/  793 batches | lr 0.000022 |  9.60 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 106 |   790/  793 batches | lr 0.000022 |  9.69 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 106 | time:  8.17s | valid loss 0.00261 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 107 |   158/  793 batches | lr 0.000021 |  9.65 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch 107 |   316/  793 batches | lr 0.000021 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 107 |   474/  793 batches | lr 0.000021 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 107 |   632/  793 batches | lr 0.000021 |  9.67 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 107 |   790/  793 batches | lr 0.000021 |  9.69 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 107 | time:  8.17s | valid loss 0.00251 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 108 |   158/  793 batches | lr 0.000020 |  9.66 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch 108 |   316/  793 batches | lr 0.000020 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 108 |   474/  793 batches | lr 0.000020 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 108 |   632/  793 batches | lr 0.000020 |  9.63 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 108 |   790/  793 batches | lr 0.000020 |  9.69 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 108 | time:  8.18s | valid loss 0.00244 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 109 |   158/  793 batches | lr 0.000019 |  9.62 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch 109 |   316/  793 batches | lr 0.000019 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 109 |   474/  793 batches | lr 0.000019 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 109 |   632/  793 batches | lr 0.000019 |  9.61 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 109 |   790/  793 batches | lr 0.000019 |  9.65 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 109 | time:  8.15s | valid loss 0.00245 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 110 |   158/  793 batches | lr 0.000018 |  9.66 ms | loss 0.00010 | ppl     1.00\n",
      "| epoch 110 |   316/  793 batches | lr 0.000018 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 110 |   474/  793 batches | lr 0.000018 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 110 |   632/  793 batches | lr 0.000018 |  9.66 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 110 |   790/  793 batches | lr 0.000018 |  9.70 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 110 | time: 10.58s | valid loss 0.00242 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 111 |   158/  793 batches | lr 0.000017 |  9.64 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch 111 |   316/  793 batches | lr 0.000017 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 111 |   474/  793 batches | lr 0.000017 |  9.75 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 111 |   632/  793 batches | lr 0.000017 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 111 |   790/  793 batches | lr 0.000017 |  9.65 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 111 | time:  8.19s | valid loss 0.00231 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 112 |   158/  793 batches | lr 0.000016 |  9.64 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch 112 |   316/  793 batches | lr 0.000016 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 112 |   474/  793 batches | lr 0.000016 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 112 |   632/  793 batches | lr 0.000016 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 112 |   790/  793 batches | lr 0.000016 |  9.69 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 112 | time:  8.17s | valid loss 0.00225 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 113 |   158/  793 batches | lr 0.000015 |  9.68 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch 113 |   316/  793 batches | lr 0.000015 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 113 |   474/  793 batches | lr 0.000015 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 113 |   632/  793 batches | lr 0.000015 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 113 |   790/  793 batches | lr 0.000015 |  9.63 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 113 | time:  8.17s | valid loss 0.00213 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 114 |   158/  793 batches | lr 0.000014 |  9.66 ms | loss 0.00009 | ppl     1.00\n",
      "| epoch 114 |   316/  793 batches | lr 0.000014 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 114 |   474/  793 batches | lr 0.000014 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 114 |   632/  793 batches | lr 0.000014 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 114 |   790/  793 batches | lr 0.000014 |  9.66 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 114 | time:  8.18s | valid loss 0.00205 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 115 |   158/  793 batches | lr 0.000014 |  9.77 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch 115 |   316/  793 batches | lr 0.000014 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 115 |   474/  793 batches | lr 0.000014 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 115 |   632/  793 batches | lr 0.000014 |  9.71 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 115 |   790/  793 batches | lr 0.000014 |  9.66 ms | loss 0.00075 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 115 | time:  8.21s | valid loss 0.00201 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 116 |   158/  793 batches | lr 0.000013 |  9.71 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch 116 |   316/  793 batches | lr 0.000013 |  9.71 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 116 |   474/  793 batches | lr 0.000013 |  9.55 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 116 |   632/  793 batches | lr 0.000013 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 116 |   790/  793 batches | lr 0.000013 |  9.67 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 116 | time:  8.19s | valid loss 0.00195 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 117 |   158/  793 batches | lr 0.000012 |  9.69 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch 117 |   316/  793 batches | lr 0.000012 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 117 |   474/  793 batches | lr 0.000012 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 117 |   632/  793 batches | lr 0.000012 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 117 |   790/  793 batches | lr 0.000012 |  9.72 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 117 | time:  8.19s | valid loss 0.00192 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 118 |   158/  793 batches | lr 0.000012 |  9.66 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch 118 |   316/  793 batches | lr 0.000012 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 118 |   474/  793 batches | lr 0.000012 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 118 |   632/  793 batches | lr 0.000012 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 118 |   790/  793 batches | lr 0.000012 |  9.70 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 118 | time:  8.19s | valid loss 0.00188 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 119 |   158/  793 batches | lr 0.000011 |  9.70 ms | loss 0.00008 | ppl     1.00\n",
      "| epoch 119 |   316/  793 batches | lr 0.000011 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 119 |   474/  793 batches | lr 0.000011 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 119 |   632/  793 batches | lr 0.000011 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 119 |   790/  793 batches | lr 0.000011 |  9.63 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 119 | time:  8.18s | valid loss 0.00186 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 120 |   158/  793 batches | lr 0.000011 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 120 |   316/  793 batches | lr 0.000011 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 120 |   474/  793 batches | lr 0.000011 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 120 |   632/  793 batches | lr 0.000011 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 120 |   790/  793 batches | lr 0.000011 |  9.68 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 120 | time: 10.61s | valid loss 0.00183 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 121 |   158/  793 batches | lr 0.000010 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 121 |   316/  793 batches | lr 0.000010 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 121 |   474/  793 batches | lr 0.000010 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 121 |   632/  793 batches | lr 0.000010 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 121 |   790/  793 batches | lr 0.000010 |  9.73 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 121 | time:  8.18s | valid loss 0.00182 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 122 |   158/  793 batches | lr 0.000010 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 122 |   316/  793 batches | lr 0.000010 |  9.70 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 122 |   474/  793 batches | lr 0.000010 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 122 |   632/  793 batches | lr 0.000010 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 122 |   790/  793 batches | lr 0.000010 |  9.71 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 122 | time:  8.20s | valid loss 0.00182 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 123 |   158/  793 batches | lr 0.000009 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 123 |   316/  793 batches | lr 0.000009 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 123 |   474/  793 batches | lr 0.000009 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 123 |   632/  793 batches | lr 0.000009 |  9.74 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 123 |   790/  793 batches | lr 0.000009 |  9.67 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 123 | time:  8.20s | valid loss 0.00179 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 124 |   158/  793 batches | lr 0.000009 |  9.80 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 124 |   316/  793 batches | lr 0.000009 |  9.70 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 124 |   474/  793 batches | lr 0.000009 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 124 |   632/  793 batches | lr 0.000009 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 124 |   790/  793 batches | lr 0.000009 |  9.69 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 124 | time:  8.21s | valid loss 0.00180 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 125 |   158/  793 batches | lr 0.000008 |  9.70 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 125 |   316/  793 batches | lr 0.000008 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 125 |   474/  793 batches | lr 0.000008 |  9.75 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 125 |   632/  793 batches | lr 0.000008 |  9.73 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 125 |   790/  793 batches | lr 0.000008 |  9.70 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 125 | time:  8.22s | valid loss 0.00176 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 126 |   158/  793 batches | lr 0.000008 |  9.74 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 126 |   316/  793 batches | lr 0.000008 |  9.66 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 126 |   474/  793 batches | lr 0.000008 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 126 |   632/  793 batches | lr 0.000008 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 126 |   790/  793 batches | lr 0.000008 |  9.72 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 126 | time:  8.21s | valid loss 0.00173 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 127 |   158/  793 batches | lr 0.000007 |  9.68 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 127 |   316/  793 batches | lr 0.000007 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 127 |   474/  793 batches | lr 0.000007 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 127 |   632/  793 batches | lr 0.000007 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 127 |   790/  793 batches | lr 0.000007 |  9.66 ms | loss 0.00074 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 127 | time:  8.19s | valid loss 0.00170 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 128 |   158/  793 batches | lr 0.000007 |  9.68 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 128 |   316/  793 batches | lr 0.000007 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 128 |   474/  793 batches | lr 0.000007 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 128 |   632/  793 batches | lr 0.000007 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 128 |   790/  793 batches | lr 0.000007 |  9.69 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 128 | time:  8.19s | valid loss 0.00167 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 129 |   158/  793 batches | lr 0.000007 |  9.66 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 129 |   316/  793 batches | lr 0.000007 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 129 |   474/  793 batches | lr 0.000007 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 129 |   632/  793 batches | lr 0.000007 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 129 |   790/  793 batches | lr 0.000007 |  9.74 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 129 | time:  8.20s | valid loss 0.00168 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 130 |   158/  793 batches | lr 0.000006 |  9.80 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 130 |   316/  793 batches | lr 0.000006 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 130 |   474/  793 batches | lr 0.000006 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 130 |   632/  793 batches | lr 0.000006 |  9.76 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 130 |   790/  793 batches | lr 0.000006 |  9.73 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 130 | time: 10.64s | valid loss 0.00166 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 131 |   158/  793 batches | lr 0.000006 |  9.64 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 131 |   316/  793 batches | lr 0.000006 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 131 |   474/  793 batches | lr 0.000006 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 131 |   632/  793 batches | lr 0.000006 |  9.72 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 131 |   790/  793 batches | lr 0.000006 |  9.74 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 131 | time:  8.20s | valid loss 0.00162 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 132 |   158/  793 batches | lr 0.000006 |  9.69 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 132 |   316/  793 batches | lr 0.000006 |  9.69 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 132 |   474/  793 batches | lr 0.000006 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 132 |   632/  793 batches | lr 0.000006 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 132 |   790/  793 batches | lr 0.000006 |  9.74 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 132 | time:  8.20s | valid loss 0.00161 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 133 |   158/  793 batches | lr 0.000005 |  9.71 ms | loss 0.00006 | ppl     1.00\n",
      "| epoch 133 |   316/  793 batches | lr 0.000005 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 133 |   474/  793 batches | lr 0.000005 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 133 |   632/  793 batches | lr 0.000005 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 133 |   790/  793 batches | lr 0.000005 |  9.64 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 133 | time:  8.19s | valid loss 0.00159 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 134 |   158/  793 batches | lr 0.000005 |  9.68 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 134 |   316/  793 batches | lr 0.000005 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 134 |   474/  793 batches | lr 0.000005 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 134 |   632/  793 batches | lr 0.000005 |  9.60 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 134 |   790/  793 batches | lr 0.000005 |  9.72 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 134 | time:  8.19s | valid loss 0.00158 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 135 |   158/  793 batches | lr 0.000005 |  9.70 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 135 |   316/  793 batches | lr 0.000005 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 135 |   474/  793 batches | lr 0.000005 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 135 |   632/  793 batches | lr 0.000005 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 135 |   790/  793 batches | lr 0.000005 |  9.68 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 135 | time:  8.20s | valid loss 0.00159 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 136 |   158/  793 batches | lr 0.000005 |  9.71 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 136 |   316/  793 batches | lr 0.000005 |  9.61 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 136 |   474/  793 batches | lr 0.000005 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 136 |   632/  793 batches | lr 0.000005 |  9.70 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 136 |   790/  793 batches | lr 0.000005 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 136 | time:  8.19s | valid loss 0.00156 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 137 |   158/  793 batches | lr 0.000004 |  9.83 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 137 |   316/  793 batches | lr 0.000004 |  9.65 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 137 |   474/  793 batches | lr 0.000004 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 137 |   632/  793 batches | lr 0.000004 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 137 |   790/  793 batches | lr 0.000004 |  9.75 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 137 | time:  8.22s | valid loss 0.00158 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 138 |   158/  793 batches | lr 0.000004 |  9.69 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 138 |   316/  793 batches | lr 0.000004 |  9.75 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 138 |   474/  793 batches | lr 0.000004 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 138 |   632/  793 batches | lr 0.000004 |  9.70 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 138 |   790/  793 batches | lr 0.000004 |  9.78 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 138 | time:  8.22s | valid loss 0.00156 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 139 |   158/  793 batches | lr 0.000004 |  9.68 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 139 |   316/  793 batches | lr 0.000004 |  9.61 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 139 |   474/  793 batches | lr 0.000004 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 139 |   632/  793 batches | lr 0.000004 |  9.72 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 139 |   790/  793 batches | lr 0.000004 |  9.71 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 139 | time:  8.20s | valid loss 0.00155 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 140 |   158/  793 batches | lr 0.000004 |  9.70 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 140 |   316/  793 batches | lr 0.000004 |  9.69 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 140 |   474/  793 batches | lr 0.000004 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 140 |   632/  793 batches | lr 0.000004 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 140 |   790/  793 batches | lr 0.000004 |  9.71 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 140 | time: 10.59s | valid loss 0.00154 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 141 |   158/  793 batches | lr 0.000004 |  9.68 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 141 |   316/  793 batches | lr 0.000004 |  9.69 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 141 |   474/  793 batches | lr 0.000004 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 141 |   632/  793 batches | lr 0.000004 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 141 |   790/  793 batches | lr 0.000004 |  9.73 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 141 | time:  8.20s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 142 |   158/  793 batches | lr 0.000003 |  9.74 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 142 |   316/  793 batches | lr 0.000003 |  9.65 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 142 |   474/  793 batches | lr 0.000003 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 142 |   632/  793 batches | lr 0.000003 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 142 |   790/  793 batches | lr 0.000003 |  9.68 ms | loss 0.00073 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 142 | time:  8.19s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 143 |   158/  793 batches | lr 0.000003 |  9.67 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 143 |   316/  793 batches | lr 0.000003 |  9.66 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 143 |   474/  793 batches | lr 0.000003 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 143 |   632/  793 batches | lr 0.000003 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 143 |   790/  793 batches | lr 0.000003 |  9.68 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 143 | time:  8.19s | valid loss 0.00154 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 144 |   158/  793 batches | lr 0.000003 |  9.70 ms | loss 0.00005 | ppl     1.00\n",
      "| epoch 144 |   316/  793 batches | lr 0.000003 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 144 |   474/  793 batches | lr 0.000003 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 144 |   632/  793 batches | lr 0.000003 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 144 |   790/  793 batches | lr 0.000003 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 144 | time:  8.19s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 145 |   158/  793 batches | lr 0.000003 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 145 |   316/  793 batches | lr 0.000003 |  9.66 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 145 |   474/  793 batches | lr 0.000003 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 145 |   632/  793 batches | lr 0.000003 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 145 |   790/  793 batches | lr 0.000003 |  9.72 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 145 | time:  8.21s | valid loss 0.00155 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 146 |   158/  793 batches | lr 0.000003 |  9.78 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 146 |   316/  793 batches | lr 0.000003 |  9.69 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 146 |   474/  793 batches | lr 0.000003 |  9.73 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 146 |   632/  793 batches | lr 0.000003 |  9.75 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 146 |   790/  793 batches | lr 0.000003 |  9.77 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 146 | time:  8.25s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 147 |   158/  793 batches | lr 0.000003 |  9.75 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 147 |   316/  793 batches | lr 0.000003 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 147 |   474/  793 batches | lr 0.000003 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 147 |   632/  793 batches | lr 0.000003 |  9.77 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 147 |   790/  793 batches | lr 0.000003 |  9.73 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 147 | time:  8.24s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 148 |   158/  793 batches | lr 0.000003 |  9.72 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 148 |   316/  793 batches | lr 0.000003 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 148 |   474/  793 batches | lr 0.000003 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 148 |   632/  793 batches | lr 0.000003 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 148 |   790/  793 batches | lr 0.000003 |  9.77 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 148 | time:  8.21s | valid loss 0.00152 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 149 |   158/  793 batches | lr 0.000002 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 149 |   316/  793 batches | lr 0.000002 |  9.63 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 149 |   474/  793 batches | lr 0.000002 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 149 |   632/  793 batches | lr 0.000002 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 149 |   790/  793 batches | lr 0.000002 |  9.71 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 149 | time:  8.19s | valid loss 0.00154 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 150 |   158/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 150 |   316/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 150 |   474/  793 batches | lr 0.000002 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 150 |   632/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 150 |   790/  793 batches | lr 0.000002 |  9.74 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time: 10.58s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 151 |   158/  793 batches | lr 0.000002 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 151 |   316/  793 batches | lr 0.000002 |  9.70 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 151 |   474/  793 batches | lr 0.000002 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 151 |   632/  793 batches | lr 0.000002 |  9.73 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 151 |   790/  793 batches | lr 0.000002 |  9.72 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 151 | time:  8.21s | valid loss 0.00152 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 152 |   158/  793 batches | lr 0.000002 |  9.71 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 152 |   316/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 152 |   474/  793 batches | lr 0.000002 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 152 |   632/  793 batches | lr 0.000002 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 152 |   790/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 152 | time:  8.20s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 153 |   158/  793 batches | lr 0.000002 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 153 |   316/  793 batches | lr 0.000002 |  9.63 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 153 |   474/  793 batches | lr 0.000002 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 153 |   632/  793 batches | lr 0.000002 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 153 |   790/  793 batches | lr 0.000002 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 153 | time:  8.18s | valid loss 0.00153 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 154 |   158/  793 batches | lr 0.000002 |  9.76 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 154 |   316/  793 batches | lr 0.000002 |  9.66 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 154 |   474/  793 batches | lr 0.000002 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 154 |   632/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 154 |   790/  793 batches | lr 0.000002 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 154 | time:  8.21s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 155 |   158/  793 batches | lr 0.000002 |  9.70 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 155 |   316/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 155 |   474/  793 batches | lr 0.000002 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 155 |   632/  793 batches | lr 0.000002 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 155 |   790/  793 batches | lr 0.000002 |  9.76 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 155 | time:  8.34s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 156 |   158/  793 batches | lr 0.000002 |  9.71 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 156 |   316/  793 batches | lr 0.000002 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 156 |   474/  793 batches | lr 0.000002 |  9.57 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 156 |   632/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 156 |   790/  793 batches | lr 0.000002 |  9.65 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 156 | time:  8.18s | valid loss 0.00152 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 157 |   158/  793 batches | lr 0.000002 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 157 |   316/  793 batches | lr 0.000002 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 157 |   474/  793 batches | lr 0.000002 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 157 |   632/  793 batches | lr 0.000002 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 157 |   790/  793 batches | lr 0.000002 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 157 | time:  8.19s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 158 |   158/  793 batches | lr 0.000002 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 158 |   316/  793 batches | lr 0.000002 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 158 |   474/  793 batches | lr 0.000002 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 158 |   632/  793 batches | lr 0.000002 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 158 |   790/  793 batches | lr 0.000002 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 158 | time:  8.19s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 159 |   158/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 159 |   316/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 159 |   474/  793 batches | lr 0.000001 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 159 |   632/  793 batches | lr 0.000001 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 159 |   790/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 159 | time:  8.18s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 160 |   158/  793 batches | lr 0.000001 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 160 |   316/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 160 |   474/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 160 |   632/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 160 |   790/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 160 | time: 10.65s | valid loss 0.00152 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 161 |   158/  793 batches | lr 0.000001 |  9.72 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 161 |   316/  793 batches | lr 0.000001 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 161 |   474/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 161 |   632/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 161 |   790/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 161 | time:  8.21s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 162 |   158/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 162 |   316/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 162 |   474/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 162 |   632/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 162 |   790/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 162 | time:  8.20s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 163 |   158/  793 batches | lr 0.000001 |  9.74 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 163 |   316/  793 batches | lr 0.000001 |  9.63 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 163 |   474/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 163 |   632/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 163 |   790/  793 batches | lr 0.000001 |  9.74 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 163 | time:  8.22s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 164 |   158/  793 batches | lr 0.000001 |  9.73 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 164 |   316/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 164 |   474/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 164 |   632/  793 batches | lr 0.000001 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 164 |   790/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 164 | time:  8.20s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 165 |   158/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 165 |   316/  793 batches | lr 0.000001 |  9.72 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 165 |   474/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 165 |   632/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 165 |   790/  793 batches | lr 0.000001 |  9.72 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 165 | time:  8.22s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 166 |   158/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 166 |   316/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 166 |   474/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 166 |   632/  793 batches | lr 0.000001 |  9.73 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 166 |   790/  793 batches | lr 0.000001 |  9.71 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 166 | time:  8.21s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 167 |   158/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 167 |   316/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 167 |   474/  793 batches | lr 0.000001 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 167 |   632/  793 batches | lr 0.000001 |  9.76 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 167 |   790/  793 batches | lr 0.000001 |  9.72 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 167 | time:  8.19s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 168 |   158/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 168 |   316/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 168 |   474/  793 batches | lr 0.000001 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 168 |   632/  793 batches | lr 0.000001 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 168 |   790/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 168 | time:  8.17s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 169 |   158/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 169 |   316/  793 batches | lr 0.000001 |  9.65 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 169 |   474/  793 batches | lr 0.000001 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 169 |   632/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 169 |   790/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 169 | time:  8.19s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 170 |   158/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 170 |   316/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 170 |   474/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 170 |   632/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 170 |   790/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 170 | time: 10.58s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 171 |   158/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 171 |   316/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 171 |   474/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 171 |   632/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 171 |   790/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 171 | time:  8.15s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 172 |   158/  793 batches | lr 0.000001 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 172 |   316/  793 batches | lr 0.000001 |  9.57 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 172 |   474/  793 batches | lr 0.000001 |  9.55 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 172 |   632/  793 batches | lr 0.000001 |  9.64 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 172 |   790/  793 batches | lr 0.000001 |  9.60 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 172 | time:  8.14s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 173 |   158/  793 batches | lr 0.000001 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 173 |   316/  793 batches | lr 0.000001 |  9.59 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 173 |   474/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 173 |   632/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 173 |   790/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 173 | time:  8.15s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 174 |   158/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 174 |   316/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 174 |   474/  793 batches | lr 0.000001 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 174 |   632/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 174 |   790/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 174 | time:  8.17s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 175 |   158/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 175 |   316/  793 batches | lr 0.000001 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 175 |   474/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 175 |   632/  793 batches | lr 0.000001 |  9.60 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 175 |   790/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 175 | time:  8.19s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 176 |   158/  793 batches | lr 0.000001 |  9.72 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 176 |   316/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 176 |   474/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 176 |   632/  793 batches | lr 0.000001 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 176 |   790/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 176 | time:  8.18s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 177 |   158/  793 batches | lr 0.000001 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 177 |   316/  793 batches | lr 0.000001 |  9.69 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 177 |   474/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 177 |   632/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 177 |   790/  793 batches | lr 0.000001 |  9.71 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 177 | time:  8.19s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 178 |   158/  793 batches | lr 0.000001 |  9.73 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 178 |   316/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 178 |   474/  793 batches | lr 0.000001 |  9.62 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 178 |   632/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 178 |   790/  793 batches | lr 0.000001 |  9.66 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 178 | time:  8.20s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 179 |   158/  793 batches | lr 0.000001 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 179 |   316/  793 batches | lr 0.000001 |  9.61 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 179 |   474/  793 batches | lr 0.000001 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 179 |   632/  793 batches | lr 0.000001 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 179 |   790/  793 batches | lr 0.000001 |  9.70 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 179 | time:  8.18s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 180 |   158/  793 batches | lr 0.000000 |  9.75 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 180 |   316/  793 batches | lr 0.000000 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 180 |   474/  793 batches | lr 0.000000 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 180 |   632/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 180 |   790/  793 batches | lr 0.000000 |  9.66 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 180 | time: 10.55s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 181 |   158/  793 batches | lr 0.000000 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 181 |   316/  793 batches | lr 0.000000 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 181 |   474/  793 batches | lr 0.000000 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 181 |   632/  793 batches | lr 0.000000 |  9.59 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 181 |   790/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 181 | time:  8.16s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 182 |   158/  793 batches | lr 0.000000 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 182 |   316/  793 batches | lr 0.000000 |  9.60 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 182 |   474/  793 batches | lr 0.000000 |  9.56 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 182 |   632/  793 batches | lr 0.000000 |  9.67 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 182 |   790/  793 batches | lr 0.000000 |  9.67 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 182 | time:  8.15s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 183 |   158/  793 batches | lr 0.000000 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 183 |   316/  793 batches | lr 0.000000 |  9.59 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 183 |   474/  793 batches | lr 0.000000 |  9.58 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 183 |   632/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 183 |   790/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 183 | time:  8.15s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 184 |   158/  793 batches | lr 0.000000 |  9.75 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 184 |   316/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 184 |   474/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 184 |   632/  793 batches | lr 0.000000 |  9.66 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 184 |   790/  793 batches | lr 0.000000 |  9.66 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 184 | time:  8.22s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 185 |   158/  793 batches | lr 0.000000 |  9.74 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 185 |   316/  793 batches | lr 0.000000 |  9.72 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 185 |   474/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 185 |   632/  793 batches | lr 0.000000 |  9.79 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 185 |   790/  793 batches | lr 0.000000 |  9.79 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 185 | time:  8.25s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 186 |   158/  793 batches | lr 0.000000 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 186 |   316/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 186 |   474/  793 batches | lr 0.000000 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 186 |   632/  793 batches | lr 0.000000 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 186 |   790/  793 batches | lr 0.000000 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 186 | time:  8.18s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 187 |   158/  793 batches | lr 0.000000 |  9.67 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 187 |   316/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 187 |   474/  793 batches | lr 0.000000 |  9.60 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 187 |   632/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 187 |   790/  793 batches | lr 0.000000 |  9.67 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 187 | time:  8.18s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 188 |   158/  793 batches | lr 0.000000 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 188 |   316/  793 batches | lr 0.000000 |  9.59 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 188 |   474/  793 batches | lr 0.000000 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 188 |   632/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 188 |   790/  793 batches | lr 0.000000 |  9.78 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 188 | time:  8.20s | valid loss 0.00151 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 189 |   158/  793 batches | lr 0.000000 |  9.75 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 189 |   316/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 189 |   474/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 189 |   632/  793 batches | lr 0.000000 |  9.62 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 189 |   790/  793 batches | lr 0.000000 |  9.74 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 189 | time:  8.21s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 190 |   158/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 190 |   316/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 190 |   474/  793 batches | lr 0.000000 |  9.59 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 190 |   632/  793 batches | lr 0.000000 |  9.63 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 190 |   790/  793 batches | lr 0.000000 |  9.74 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 190 | time: 10.51s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 191 |   158/  793 batches | lr 0.000000 |  9.61 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 191 |   316/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 191 |   474/  793 batches | lr 0.000000 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 191 |   632/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 191 |   790/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 191 | time:  8.18s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 192 |   158/  793 batches | lr 0.000000 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 192 |   316/  793 batches | lr 0.000000 |  9.62 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 192 |   474/  793 batches | lr 0.000000 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 192 |   632/  793 batches | lr 0.000000 |  9.76 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 192 |   790/  793 batches | lr 0.000000 |  9.81 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 192 | time:  8.23s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 193 |   158/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 193 |   316/  793 batches | lr 0.000000 |  9.70 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 193 |   474/  793 batches | lr 0.000000 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 193 |   632/  793 batches | lr 0.000000 |  9.69 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 193 |   790/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 193 | time:  8.20s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 194 |   158/  793 batches | lr 0.000000 |  9.76 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 194 |   316/  793 batches | lr 0.000000 |  9.69 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 194 |   474/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 194 |   632/  793 batches | lr 0.000000 |  9.75 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 194 |   790/  793 batches | lr 0.000000 |  9.78 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 194 | time:  8.24s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 195 |   158/  793 batches | lr 0.000000 |  9.72 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 195 |   316/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 195 |   474/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 195 |   632/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 195 |   790/  793 batches | lr 0.000000 |  9.75 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 195 | time:  8.23s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 196 |   158/  793 batches | lr 0.000000 |  9.73 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 196 |   316/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 196 |   474/  793 batches | lr 0.000000 |  9.77 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 196 |   632/  793 batches | lr 0.000000 |  9.79 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 196 |   790/  793 batches | lr 0.000000 |  9.77 ms | loss 0.00071 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 196 | time:  8.26s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 197 |   158/  793 batches | lr 0.000000 |  9.66 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 197 |   316/  793 batches | lr 0.000000 |  9.70 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 197 |   474/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 197 |   632/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 197 |   790/  793 batches | lr 0.000000 |  9.75 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 197 | time:  8.21s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 198 |   158/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 198 |   316/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 198 |   474/  793 batches | lr 0.000000 |  9.63 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 198 |   632/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 198 |   790/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 198 | time:  8.19s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 199 |   158/  793 batches | lr 0.000000 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 199 |   316/  793 batches | lr 0.000000 |  9.64 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 199 |   474/  793 batches | lr 0.000000 |  9.68 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 199 |   632/  793 batches | lr 0.000000 |  9.80 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 199 |   790/  793 batches | lr 0.000000 |  9.73 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 199 | time:  8.23s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 200 |   158/  793 batches | lr 0.000000 |  9.69 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 200 |   316/  793 batches | lr 0.000000 |  9.74 ms | loss 0.00003 | ppl     1.00\n",
      "| epoch 200 |   474/  793 batches | lr 0.000000 |  9.65 ms | loss 0.00004 | ppl     1.00\n",
      "| epoch 200 |   632/  793 batches | lr 0.000000 |  9.71 ms | loss 0.00007 | ppl     1.00\n",
      "| epoch 200 |   790/  793 batches | lr 0.000000 |  9.70 ms | loss 0.00072 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 200 | time: 10.63s | valid loss 0.00150 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# S is the source sequence length\n",
    "# T is the target sequence length\n",
    "# N is the batch size\n",
    "# E is the feature number\n",
    "\n",
    "#src = torch.rand((10, 32, 512)) # (S,N,E) \n",
    "#tgt = torch.rand((20, 32, 512)) # (T,N,E)\n",
    "#out = transformer_model(src, tgt)\n",
    "\n",
    "input_window = 200 # number of input steps\n",
    "output_window = 1 # number of prediction steps, in this model its fixed to one\n",
    "batch_size = 10 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "          \n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "# if window is 100 and prediction step is 1\n",
    "# in -> [0..99]\n",
    "# target -> [1..100]\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "def get_data():\n",
    "       \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    #loading series data from a file\n",
    "    #from pandas import read_csv\n",
    "    #series = pd.read_csv('/content/AAPL.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "    \n",
    "    #Choose arbitrary tech\n",
    "    y.pdr_override()\n",
    "    apple = pdr.get_data_yahoo(tickers = tickers, period = \"max\", interval = \"1d\", auto_adjust = True, prepost = False)\n",
    "\n",
    "    apple = pd.DataFrame(apple)\n",
    "    #print(apple['Open'].count())\n",
    "\n",
    "    apple_train = pd.DataFrame(apple[0:8132])\n",
    "    apple_test = pd.DataFrame(apple[8132:])\n",
    "\n",
    "\n",
    "    train_open = apple_train['Open'].to_numpy()\n",
    "    train_high = apple_train['High'].to_numpy()\n",
    "    train_low = apple_train['Low'].to_numpy()\n",
    "    train_volume = apple_train['Volume'].to_numpy()\n",
    "    train_close = apple_train['Close'].to_numpy()\n",
    "    \n",
    "    test_open = apple_test['Open'].to_numpy()\n",
    "    test_high = apple_test['High'].to_numpy()\n",
    "    test_low = apple_test['Low'].to_numpy()\n",
    "    test_volume = apple_test['Volume'].to_numpy()\n",
    "    test_close = apple_test['Close'].to_numpy()\n",
    "\n",
    "    # looks like normalizing input values critical for the model\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    #amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    apple_train = scaler.fit_transform(apple_train.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    train_close = scaler.fit_transform(train_close.reshape(-1, 1)).reshape(-1)\n",
    "    train_high = scaler.fit_transform(train_high.reshape(-1, 1)).reshape(-1)\n",
    "    train_low = scaler.fit_transform(train_low.reshape(-1, 1)).reshape(-1)\n",
    "    train_volume = scaler.fit_transform(train_volume.reshape(-1, 1)).reshape(-1)\n",
    "    #close = scaler.fit_transform(full_data['Close'].reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    apple_test = scaler.fit_transform(apple_test.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    test_close = scaler.fit_transform(test_close.reshape(-1, 1)).reshape(-1)\n",
    "    test_high = scaler.fit_transform(test_high.reshape(-1, 1)).reshape(-1)\n",
    "    test_low = scaler.fit_transform(test_low.reshape(-1, 1)).reshape(-1)\n",
    "    test_volume = scaler.fit_transform(test_volume.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    #split into train_data and test_data\n",
    "    #samples = 2516\n",
    "    #train_data = close[:int(samples*0.8)]\n",
    "    #test_data = close[int(samples*0.8):]\n",
    "\n",
    "    samples = 8132\n",
    "    train_data = train_close\n",
    "    test_data = test_close\n",
    "\n",
    "    # convert our train data into a pytorch train tensor\n",
    "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
    "    # todo: add comment.. \n",
    "    train_sequence = create_inout_sequences(train_data,input_window)\n",
    "    train_sequence = train_sequence[:-output_window] #todo: fix hack? -> din't think this through, looks like the last n sequences are to short, so I just remove them. Hackety Hack.. \n",
    "\n",
    "    #test_data = torch.FloatTensor(test_data).view(-1) \n",
    "    test_data = create_inout_sequences(test_data,input_window)\n",
    "    test_data = test_data[:-output_window] #todo: fix hack?\n",
    "\n",
    "    return train_sequence.to(device),test_data.to(device)\n",
    "\n",
    "def get_batch(source, i,batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]    \n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target\n",
    "\n",
    "\n",
    "def train(train_data):\n",
    "    model.train() # Turn on the train mode \\o/\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        data, targets = get_batch(train_data, i,batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_data) / batch_size / 5)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def plot_and_loss(eval_model, data_source,epoch):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i,1)\n",
    "            output = eval_model(data)            \n",
    "            total_loss += criterion(output, target).item()\n",
    "            test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0)\n",
    "            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
    "            \n",
    "    #test_result = test_result.cpu().numpy() -> no need to detach stuff.. \n",
    "    len(test_result)\n",
    "\n",
    "    pyplot.plot(test_result,color=\"red\", label = 'Test result')\n",
    "    pyplot.plot(truth[:500],color=\"blue\", label = 'Actual Close')\n",
    "    #pyplot.plot(test_result-truth,color=\"green\", label = 'Test result - Actual Close')\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.legend(loc = 'upper left')\n",
    "    pyplot.savefig('transformer-epoch%d.png'%epoch)\n",
    "    pyplot.close()\n",
    "    \n",
    "    return total_loss / i\n",
    "\n",
    "\n",
    "# predict the next n steps based on the input data \n",
    "def predict_future(eval_model, data_source,steps):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    data, _ = get_batch(data_source, 0,1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps):            \n",
    "            output = eval_model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "            \n",
    "    data = data.cpu().view(-1)\n",
    "    \n",
    "    # I used this plot to visualize if the model picks up any long term structure within the data. \n",
    "    pyplot.plot(data,color=\"red\", label = 'Predictions for next steps')       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\", label = 'Close values')    \n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.legend(loc = 'upper left')\n",
    "    pyplot.savefig('transformer-future%d.png'%steps)\n",
    "    pyplot.close()\n",
    "        \n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    eval_batch_size = 1000\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
    "            output = eval_model(data)            \n",
    "            total_loss += len(data[0])* criterion(output, targets).cpu().item()\n",
    "    return total_loss / len(data_source)\n",
    "\n",
    "train_data, val_data = get_data()\n",
    "model = TransAm().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.005 \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 200 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_data)\n",
    "    \n",
    "    if(epoch % 10 is 0):\n",
    "        val_loss = plot_and_loss(model, val_data,epoch)\n",
    "        predict_future(model, val_data, 200)\n",
    "    else:\n",
    "        val_loss = evaluate(model, val_data)\n",
    "   \n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    #if val_loss < best_val_loss:\n",
    "    #    best_val_loss = val_loss\n",
    "    #    best_model = model\n",
    "\n",
    "    scheduler.step() \n",
    "\n",
    "#src = torch.rand(input_window, batch_size, 1) # (source sequence length,batch size,feature number) \n",
    "#out = model(src)\n",
    "#\n",
    "#print(out)\n",
    "#print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1706868,
     "status": "ok",
     "timestamp": 1618002320359,
     "user": {
      "displayName": "Shambhavi Roy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHiQqxbmodLU_HOy13XxpMDhAfI1I9CoIrcMpE=s64",
      "userId": "17314445049898465098"
     },
     "user_tz": 240
    },
    "id": "kZEfzD8OQ-YZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "E6895_Transformers_Single_step-4/9/21.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
